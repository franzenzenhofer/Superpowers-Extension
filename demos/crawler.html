<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8"/>
  <meta name="superpowers" content="enabled"/>
  <title>Superpowers Demo: Domain Crawler</title>
  <style>
    :root {
      --excel-header: #217346;
      --excel-grid: #e6e6e6;
      --excel-hover: #f3f3f3;
      --excel-selected: #d3f0e0;
    }
    body {
      margin: 0;
      padding: 20px;
      font-family: 'Segoe UI', sans-serif;
      background: #f8f9fa;
    }
    .excel-container {
      background: white;
      border: 1px solid #ccc;
      border-radius: 4px;
      box-shadow: 0 2px 6px rgba(0,0,0,0.1);
      padding: 20px;
    }
    .control-panel {
      display: grid;
      grid-template-columns: 1fr auto auto auto;
      gap: 15px;
      align-items: center;
      background: var(--excel-header);
      padding: 15px;
      border-radius: 4px;
      color: white;
    }
    .url-input {
      display: flex;
      align-items: center;
      background: white;
      border-radius: 3px;
      padding: 2px;
    }
    .url-input input {
      flex: 1;
      padding: 8px;
      border: none;
      outline: none;
      font-size: 14px;
    }
    .excel-button {
      background: white;
      border: none;
      padding: 8px 16px;
      border-radius: 3px;
      font-weight: 600;
      cursor: pointer;
      transition: background 0.2s;
    }
    .excel-button:hover {
      background: var(--excel-hover);
    }
    .excel-button.start {
      background: #217346;
      color: white;
    }
    .excel-button.stop {
      background: #d64045;
      color: white;
    }
    .excel-button.export {
      background: #0078d4;
      color: white;
    }
    .grid-container {
      margin-top: 20px;
      border: 1px solid var(--excel-grid);
      border-radius: 4px;
      overflow: hidden;
    }
    .grid-header {
      display: grid;
      grid-template-columns: 40px 3fr 1fr 1fr 1fr 1fr;
      background: var(--excel-header);
      color: white;
      font-weight: 600;
      padding: 10px;
      gap: 10px;
    }
    .grid-body {
      max-height: 600px;
      overflow-y: auto;
    }
    .grid-row {
      display: grid;
      grid-template-columns: 40px 3fr 1fr 1fr 1fr 1fr;
      padding: 8px 10px;
      border-bottom: 1px solid var(--excel-grid);
      gap: 10px;
      transition: background 0.2s;
    }
    .grid-row:hover {
      background: var(--excel-hover);
    }
    .stats-panel {
      display: flex;
      gap: 20px;
      margin-top: 15px;
      padding: 10px;
      background: #f8f9fa;
      border-radius: 4px;
    }
    .stat-item {
      display: flex;
      align-items: center;
      gap: 5px;
    }
    .stat-value {
      font-weight: 600;
      color: var(--excel-header);
    }
    .status-200 { color: #217346; }
    .status-300 { color: #0078d4; }
    .status-400 { color: #d83b01; }
    .status-500 { color: #d64045; }
    .progress-bar {
      height: 4px;
      background: #eee;
      margin-top: 10px;
      border-radius: 2px;
      overflow: hidden;
    }
    .progress-fill {
      height: 100%;
      background: var(--excel-header);
      width: 0%;
      transition: width 0.3s;
    }
    .debug-output {
      margin-top: 10px;
      font-size: 0.85em;
      max-height: 200px;
      overflow-y: auto;
      background: #f1f1f1;
      padding: 10px;
      border-radius: 4px;
      display: none;
    }
  </style>
</head>
<body>
  <h1>Superpowers Demo: Domain Crawler</h1>
  <p>
    This page uses <code>Superpowers.fetch</code> to crawl a domain (via BFS) from a start URL,
    restricted to the same domain. It parses each page for status code, title, first &lt;h1&gt;, 
    and found links. Results are shown in an Excel-like grid below.  
    Logging is done via <code>Superpowers.debugLog(...)</code>.
  </p>

  <div class="excel-container">
    <div class="control-panel">
      <div class="url-input">
        <input type="text" id="startUrl" placeholder="Enter starting URL" 
               value="https://www.fullstackoptimization.com"/>
      </div>
      <button id="startBtn" class="excel-button start">Start</button>
      <button id="stopBtn" class="excel-button stop">Stop</button>
      <button id="exportBtn" class="excel-button export">Export CSV</button>
    </div>

    <div class="stats-panel">
      <div class="stat-item">
        <span>Pages Crawled:</span>
        <span id="pageCount" class="stat-value">0</span>
      </div>
      <div class="stat-item">
        <span>Queue Size:</span>
        <span id="queueSize" class="stat-value">0</span>
      </div>
      <div class="stat-item">
        <span>Time Elapsed:</span>
        <span id="timeElapsed" class="stat-value">00:00</span>
      </div>
    </div>

    <div class="progress-bar">
      <div id="progressFill" class="progress-fill"></div>
    </div>

    <div class="grid-container">
      <div class="grid-header">
        <div>#</div>
        <div>URL</div>
        <div>Status</div>
        <div>Title</div>
        <div>H1</div>
        <div>Links Found</div>
      </div>
      <div id="results" class="grid-body"></div>
    </div>
  </div>

  <div id="debugOutput" class="debug-output"></div>

  <script>
    let crawling = false;
    let queue = [];
    let visited = new Set();
    let startTime = 0;
    let timerInterval = null;
    let crawlData = []; // to store for CSV export

    const resultsDiv   = document.getElementById('results');
    const startInput   = document.getElementById('startUrl');
    const startBtn     = document.getElementById('startBtn');
    const stopBtn      = document.getElementById('stopBtn');
    const exportBtn    = document.getElementById('exportBtn');
    const pageCountEl  = document.getElementById('pageCount');
    const queueSizeEl  = document.getElementById('queueSize');
    const timeElapsedEl= document.getElementById('timeElapsed');
    const progressFill = document.getElementById('progressFill');
    const debugOutput  = document.getElementById('debugOutput');

    const MAX_PAGES = Infinity;

    // We'll store logs in the UI as well:
    function localDebugLine(msg) {
      debugOutput.style.display = 'block';
      debugOutput.textContent += (msg + "\n");
      debugOutput.scrollTop = debugOutput.scrollHeight;
    }

    // For extension-based logging, we call "window.Superpowers.debugLog(...)"
    function extensionDebugLog(msg, level = "info") {
      if (window.Superpowers && typeof window.Superpowers.debugLog === "function") {
        window.Superpowers.debugLog(msg, level);
      }
      // Also show in the local debug panel
      localDebugLine(msg);
    }

    function logRow(index, url, status, title, h1, linksFound) {
      const row = document.createElement('div');
      row.className = 'grid-row';

      const safeUrl   = url   || '';
      const safeTitle = title || '';
      const safeH1    = h1    || '';

      row.innerHTML = `
        <div>${index}</div>
        <div title="${safeUrl}">
          ${safeUrl.substring(0, 50)}${(safeUrl.length > 50) ? '...' : ''}
        </div>
        <div class="${getStatusClass(status)}">${status || ''}</div>
        <div title="${safeTitle}">
          ${safeTitle.substring(0, 30)}${(safeTitle.length > 30) ? '...' : ''}
        </div>
        <div title="${safeH1}">
          ${safeH1.substring(0, 30)}${(safeH1.length > 30) ? '...' : ''}
        </div>
        <div>${linksFound || 0}</div>
      `;
      resultsDiv.appendChild(row);
      resultsDiv.scrollTop = resultsDiv.scrollHeight;

      // Store data for CSV export
      crawlData.push({
        index,
        url,
        status,
        title,
        h1,
        linksFound
      });
    }

    async function crawlDomain(startUrl) {
      crawling = true;
      pageCountEl.textContent = '0';
      queueSizeEl.textContent = '0';
      visited.clear();
      queue = [];
      crawlData = [];

      visited.add(startUrl);
      queue.push(startUrl);

      startTime = Date.now();
      if (timerInterval) clearInterval(timerInterval);
      timerInterval = setInterval(updateTimer, 1000);

      const domain = extractDomain(startUrl);
      extensionDebugLog(`Starting BFS from ${startUrl}, domain: ${domain}`, "info");

      let pageCount = 0;

      while (crawling && queue.length > 0 && pageCount < MAX_PAGES) {
        const currentUrl = queue.shift();
        pageCount++;
        updateStats(pageCount, queue.length);
        await crawlOnePage(currentUrl, domain, pageCount);

        // Keep going until queue is empty or manually stopped
        if (!crawling) {
          extensionDebugLog(`Crawl manually stopped at page #${pageCount}`, "warning");
          break;
        }
      }

      extensionDebugLog("Crawl ended.", "info");
      clearInterval(timerInterval);
      crawling = false;
    }

    async function crawlOnePage(url, domain, index) {
      extensionDebugLog(`crawlOnePage => #${index} : ${url}`, "info");

      if (!window.Superpowers || typeof window.Superpowers.fetch !== "function") {
        extensionDebugLog("No Superpowers.fetch available. Is the extension enabled?", "error");
        return;
      }

      try {
        const resp = await window.Superpowers.fetch(url);
        extensionDebugLog(`  => status: ${resp.status}, length: ${resp.headers["content-length"] || "unknown"}`, "info");

        // parse the body as HTML
        const parser = new DOMParser();
        const doc = parser.parseFromString(await resp.text(), 'text/html');
        const titleEl = doc.querySelector('title');
        const titleText = titleEl ? titleEl.innerText.trim() : '';

        const h1El = doc.querySelector('h1');
        const h1Text = h1El ? h1El.innerText.trim() : '';

        const aTags = doc.querySelectorAll('a[href]');
        let newCount = 0;
        aTags.forEach(a => {
          const href = a.getAttribute('href');
          const absoluteUrl = toAbsoluteUrl(href, url);
          if (!absoluteUrl) return;
          const thisDomain = extractDomain(absoluteUrl);

          // BFS within same domain, keep fragments
          if (thisDomain === domain && !visited.has(absoluteUrl)) {
            visited.add(absoluteUrl);
            queue.push(absoluteUrl);
            newCount++;
          }
        });

        logRow(index, url, resp.status, titleText, h1Text, newCount);
      } catch (err) {
        extensionDebugLog(`Crawl error on ${url}: ${err}`, "error");
        logRow(index, url, 'ERR', '', '', 0);
      }
    }

    function extractDomain(url) {
      try {
        return new URL(url).hostname;
      } catch (e) {
        return '';
      }
    }

    function toAbsoluteUrl(href, baseUrl) {
      if (!href) return '';
      try {
        // preserves # fragments
        return new URL(href, baseUrl).href; 
      } catch (e) {
        return '';
      }
    }

    function updateStats(pageCount, queueSize) {
      pageCountEl.textContent = pageCount;
      queueSizeEl.textContent = queueSize;
      const pct = (pageCount / (MAX_PAGES === Infinity ? (pageCount || 1) : MAX_PAGES)) * 100;
      progressFill.style.width = Math.min(pct, 100) + '%';
    }

    function updateTimer() {
      const elapsed = Math.floor((Date.now() - startTime) / 1000);
      const minutes = Math.floor(elapsed / 60).toString().padStart(2, '0');
      const seconds = (elapsed % 60).toString().padStart(2, '0');
      timeElapsedEl.textContent = `${minutes}:${seconds}`;
    }

    function getStatusClass(status) {
      const code = parseInt(status, 10);
      if (Number.isNaN(code)) return '';
      if (code >= 500) return 'status-500';
      if (code >= 400) return 'status-400';
      if (code >= 300) return 'status-300';
      return 'status-200';
    }

    function exportToCSV() {
      if (!crawlData.length) {
        alert('No crawl data to export.');
        return;
      }
      let csvContent = 'data:text/csv;charset=utf-8,';
      csvContent += 'Index,URL,Status,Title,H1,LinksFound\n';
      crawlData.forEach(item => {
        const row = [
          item.index,
          `"${item.url}"`,
          `"${item.status}"`,
          `"${item.title.replace(/"/g, '""')}"`,
          `"${item.h1.replace(/"/g, '""')}"`,
          item.linksFound
        ].join(',');
        csvContent += row + '\n';
      });
      const encodedUri = encodeURI(csvContent);
      const link = document.createElement('a');
      link.setAttribute('href', encodedUri);
      link.setAttribute('download', 'crawl_results.csv');
      document.body.appendChild(link);
      link.click();
      document.body.removeChild(link);
    }

    // Event listeners
    startBtn.addEventListener('click', () => {
      if (crawling) {
        alert('Crawler is already running. Please stop it first.');
        return;
      }
      const url = startInput.value.trim();
      if (!url) {
        alert('Please enter a valid start URL.');
        return;
      }
      resultsDiv.replaceChildren();
      progressFill.style.width = '0%';
      pageCountEl.textContent = '0';
      queueSizeEl.textContent = '0';
      timeElapsedEl.textContent = '00:00';
      crawlDomain(url);
    });

    stopBtn.addEventListener('click', () => {
      if (!crawling) {
        alert('Not currently crawling.');
        return;
      }
      crawling = false;
      clearInterval(timerInterval);
      extensionDebugLog('Stop requested by user.', "warning");
    });

    exportBtn.addEventListener('click', exportToCSV);
  </script>
</body>
</html>
